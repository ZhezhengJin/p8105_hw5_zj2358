---
title: "P8105_hw5"
author: "Zhezheng Jin"
date: "2023-11-10"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(knitr)
library(janitor)

opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

#### Data import
```{r message=F}
homicide <- read_csv("./data_file/homicide-data.csv")

homicide
```
Description: 

This dataset has `r nrow(homicide)` observations and `r ncol(homicide)` variables.
There are `r nrow(homicide)` number of observations of homicide cases in the 50 large U.S. cities and `r ncol(homicide)`  variables, including `r names(homicide)`. 

#### Homicides within cities
```{r}
homicide <-homicide %>%
  mutate(
    city_state = paste(city, state, sep=", "),
    unsolved = disposition %in% c("Closed without arrest", "Open/No arrest")
    ) %>%
  filter(city_state != "Tulsa, AL")

cities_sum <- homicide %>%
  group_by(city_state) %>%
  summarise(
    total_homicides = n(),
    unsolved_homicides = sum(unsolved, na.rm = TRUE)
  )

cities_sum
```

#### Baltimore summary
```{r}
baltimore_sum <-  
  cities_sum %>%
  filter(city_state == "Baltimore, MD")
baltimore_test <-
  prop.test(
  x = baltimore_sum %>% pull(unsolved_homicides),
  n = baltimore_sum %>% pull(total_homicides)
  ) %>%
  broom::tidy()

baltimore_test
```

#### Summary of each city
```{r}
prop_test_city <- function(unsolved, total) {
    test_result <- prop.test(x = unsolved, n = total)
    return(test_result)
    }

cities_proportion <- cities_sum %>%
  mutate(
    prop_test_result = map2(unsolved_homicides, total_homicides, prop_test_city),
    tidy_results = map(prop_test_result, broom::tidy)
  ) %>%
  select(city_state, tidy_results) %>%
  unnest(tidy_results) %>%
  select(city_state, estimate, conf.low, conf.high)

cities_proportion
```


#### Plot: Estimated proportion of unsolved homicides & CIs by city
```{r}
cities_proportion %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>%
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

## Problem 2

#### Data import and combination
```{r message=F}
df <- 
  tibble(list.files("./data_file/data_q2")) %>%
  mutate(file_list = paste(list.files("./data_file/data_q2")))

read_files <- function(x) {
  
    data = read_csv(paste0("./data_file/data_q2/", x)) %>%
      mutate(file_names = x)
}

longitudinal_data <- map_df(df$file_list, read_files)

longitudinal_data
```

#### Tidy dataset
```{r}
longitudinal_tidy <- longitudinal_data %>%
  clean_names() %>%
  mutate(group = ifelse(grepl("con", file_names), "Control", "Experimental")) %>%
  mutate(subject_ID = as.integer(str_extract(file_names, "[0-9][0-9]"))) %>%
  select(-file_names) %>%
  pivot_longer(
    cols = starts_with("week"),
    names_to = "week",
    values_to = "observation"
  ) %>%
  mutate(week = as.numeric(gsub("week_", "", week)))

longitudinal_tidy
```

#### Spaghetti plot: Observations on Each Subject over 8 Weeks between Two Groups
```{r}
longitudinal_tidy %>% 
  ggplot(aes(x = week, y =observation, color = as.factor(subject_ID))) +
  geom_point(size=0.2) +
  geom_line(aes(group = subject_ID), alpha=0.5) +
  facet_grid(~group) +
  labs(x = "Week", y = "Observation", col = "Subject ID")
```

This plot reveals a distinct contrast between the control and experimental groups: the control group's observations fluctuate significantly over the eight-week period without exhibiting a clear trend, suggesting high variability and no consistent response. In contrast, the experimental group displays a pronounced upward trend in observations, implying a systematic increase over time which suggests that the experimental condition or treatment might be having a positive and more uniform effect on the subjects. 

## Problem 3

#### Set Parameters 
```{r}
n <- 30
sigma <- 5
alpha <- 0.05
mus <- c(0, 1, 2, 3, 4, 5, 6)
set.seed(1)
```

#### Define the function for mu and sigma
```{r}
sim_mean_sd = function(n, mu, sigma) {
  
  sim_data = tibble(
    x = rnorm(n, mean = mu, sd = sigma),
  )
  
  sim_data |> 
    summarize(
      mu_hat = mean(x),
      sigma_hat = sd(x)
    )
}
```

#### Define a function for the t-test
```{r}
perform_t_test <- function(n, mu, sigma) {
  sample <- rnorm(n, mean = mu, sd = sigma)
  test_result <- t.test(sample, mu = 0)
  broom::tidy(test_result)
}
```

#### Initialize data frame to store results
```{r}
results <- tibble(mu = numeric(), mu_hat = numeric(), p_value = numeric(), reject = logical())
```

#### Simulation loop
```{r}
for (mu in mus) {
  for (i in 1:5000) {
    sim_results <- sim_mean_sd(n, mu, sigma)
    t_test_results <- perform_t_test(n, mu, sigma)
    results <- results %>% 
      add_row(mu = mu, 
              mu_hat = sim_results$mu_hat, 
              p_value = t_test_results$p.value, 
              reject = t_test_results$p.value < alpha)
  }
}
```
    
#### Power Calculation
```{r}
power_results <- results %>% 
  group_by(mu) %>% 
  summarise(power = mean(reject), 
            avg_mu_hat = mean(mu_hat), 
            avg_mu_hat_rejected = mean(mu_hat[reject]))
```


#### Plot: power vs mu
```{r}
power_results %>% 
  ggplot(aes(x = mu, y = power)) +
  geom_point() +
  geom_line() +
  labs(title = "Power vs. True Mean", x = "True Mean (mu)", y = "Power")
```
The graph illustrates a positive association between effect size and power: as the true mean, representing the effect size, increases, so does the power of the test. This reflects the principle that larger effects are easier to detect, thereby increasing the likelihood of correctly rejecting the null hypothesis when it is indeed false.

#### Plot: average mu_hat vs mu
```{r}
power_results %>% 
  ggplot(aes(x = mu)) +
  geom_point(aes(y = avg_mu_hat, color = "Average Estimate"), shape = 1) +  
  geom_line(aes(y = avg_mu_hat, color = "Average Estimate")) +
  geom_point(aes(y = avg_mu_hat_rejected, color = "Conditional Average Estimate"), shape = 2) +
  geom_line(aes(y = avg_mu_hat_rejected, color = "Conditional Average Estimate"), linetype = "dashed") +
  labs(
    title = "Average Estimated Mean vs. True Mean",
    x = "True Mean (mu)",
    y = "Average Estimated Mean",
    color = "mu_hat"
  ) +
  scale_color_manual(
    values = c("Average Estimate" = "blue", "Conditional Average Estimate" = "red")
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")
```
The plot indicates that the sample average of mean (μ^) in tests where the null hypothesis is rejected closely approximates the true mean (μ), as demonstrated by the overlapping lines for average estimates and conditional average estimates. This suggests that the t-test is an unbiased estimator of the population mean when the null is rejected, which is consistent with the properties of the t-test under the assumed conditions of the simulation. 



